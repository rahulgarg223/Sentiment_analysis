{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Annalysis Using Complement Naive Bayes**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "L-LKpk3ZVFqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "import re\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Function to tokenize and clean the text\n",
        "def tokenize(text):\n",
        "    text = text.lower() # Convert to lowercase\n",
        "    text = re.sub(r'\\W+', ' ', text) # Remove punctuation\n",
        "    tokens = text.split() # Split into tokens\n",
        "    return tokens\n",
        "\n",
        "# Function to count word frequencies\n",
        "def count_words(data):\n",
        "    word_counts = defaultdict(lambda: {'neutral': 0, 'positive': 0, 'negative': 0})\n",
        "    for text, sentiment in data:\n",
        "        tokens = tokenize(text)\n",
        "        for token in tokens:\n",
        "            word_counts[token][sentiment] += 1\n",
        "    return word_counts\n",
        "\n",
        "# Function to calculate word probabilities\n",
        "def word_probabilities(word_counts, total_neutral, total_pos, total_neg, smoothing=1):\n",
        "    probabilities = defaultdict(dict)\n",
        "    for word in word_counts:\n",
        "        probabilities[word]['neutral'] = \\\n",
        "          (total_neutral - word_counts[word]['neutral'] + smoothing) / (total_neutral + smoothing)\n",
        "        probabilities[word]['positive'] = \\\n",
        "          (total_pos - word_counts[word]['positive'] + smoothing) / (total_pos + smoothing)\n",
        "        probabilities[word]['negative'] = \\\n",
        "          (total_neg - word_counts[word]['negative'] + smoothing) / (total_neg + smoothing)\n",
        "    return probabilities\n",
        "\n",
        "# Function to classify a new text\n",
        "def classify(text, word_probs, prior_neutral, prior_pos, prior_neg):\n",
        "    text_tokens = tokenize(text)\n",
        "    neutral_prob = prior_neutral\n",
        "    pos_prob = prior_pos\n",
        "    neg_prob = prior_neg\n",
        "    for token in text_tokens:\n",
        "        if token in word_probs:\n",
        "            neutral_prob *= word_probs[token]['neutral']\n",
        "            pos_prob *= word_probs[token]['positive']\n",
        "            neg_prob *= word_probs[token]['negative']\n",
        "    probabilities = {'neutral': neutral_prob, 'positive': pos_prob, 'negative': neg_prob}\n",
        "    return max(probabilities, key=probabilities.get)\n",
        "\n",
        "# Read the data\n",
        "train_df = pd.read_csv('/content/test.csv', encoding='unicode_escape')\n",
        "\n",
        "# Preprocess the data\n",
        "train_data = train_df[['text', 'sentiment']].dropna().values.tolist()\n",
        "\n",
        "# Count total samples for each sentiment\n",
        "total_neutral = sum(1 for _, sentiment in train_data if sentiment == 'neutral')\n",
        "total_pos = sum(1 for _, sentiment in train_data if sentiment == 'positive')\n",
        "total_neg = sum(1 for _, sentiment in train_data if sentiment == 'negative')\n",
        "\n",
        "# Train the classifier\n",
        "word_counts = count_words(train_data)\n",
        "word_probs = word_probabilities(word_counts, total_neutral, total_pos, total_neg)\n",
        "prior_neutral = total_neutral / len(train_data)\n",
        "prior_pos = total_pos / len(train_data)\n",
        "prior_neg = total_neg / len(train_data)\n",
        "\n",
        "# Test the classifier\n",
        "test_df = pd.read_csv('/content/test.csv', encoding='unicode_escape')\n",
        "test_data = test_df[['text', 'sentiment']].dropna().values.tolist()\n",
        "\n",
        "predictions = [classify(text, word_probs, prior_neutral, prior_pos, prior_neg) for text, _ in test_data]\n",
        "true_labels = [sentiment for _, sentiment in test_data]\n",
        "\n",
        "\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions, labels=['neutral', 'positive', 'negative'])\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "141JS9wjWSOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4560a4f6-6c87-47d7-c887-4fa2bb39ebb8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1412   18    0]\n",
            " [1103    0    0]\n",
            " [ 989   12    0]]\n",
            "Accuracy: 0.39954725523486134\n"
          ]
        }
      ]
    }
  ]
}